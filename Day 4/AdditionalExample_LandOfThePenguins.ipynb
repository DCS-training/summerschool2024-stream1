{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDCS Summer School\n",
    "## Additional Examples: Collections, List Comprehensions and Loops\n",
    "\n",
    "Once upon a time there was an ancient civilisation...the land of the penguins. The land spanned far across the world and was vast and icy with majestic glaciers, snow-capped mountains and regal penguins. Sadly over decades the land was lost but many led expeditions to recover the ancient texts of the land of the penguins. Many explorers navigated through icy terrain, examining ancient artifacts and climibing the icy cliffs. Finally one day they found a grand temple which hid the treasures they sought. The great explorer Christopher Pingu discovered the ancient texts inside and with deep concentration examined them and wrote down information in the icy caves...\n",
    "\n",
    "Even to the modern day, the texts are still examined and taught about in all aspects of penguin school. In particular within the computing classes in every school the data is used to teach penguins around the world how to brudge the past and present through data analysis and coding. One day a portal opened up between the penguin and human world and through it, only one thing was passed to the human world...the documents of the ancient civilisation of the land of the penguins! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    (\"Letter from Emperor Icebeak\", \"Letter\", \"Emperor Icebeak\", 1203),\n",
    "    (\"Diary of Explorer Frostfeather\", \"Diary\", \"Explorer Frostfeather\", 1302),\n",
    "    (\"Proclamation of the Great Snowfall\", \"Edict\", \"Council of Penguins\", 1150),\n",
    "    (\"Chronicler's Tale of the Frozen Flock\", \"Chronicle\", \"Chronicler Flipper\", 1401),\n",
    "    (\"Letter from Admiral Snowclaw\", \"Letter\", \"Admiral Snowclaw\", 1256),\n",
    "    (\"Edict of the Eternal Winter\", \"Edict\", \"Empress Frostwing\", 1189),\n",
    "    (\"Diary of Fisher Penguino\", \"Diary\", \"Fisher Penguino\", 1320),\n",
    "    (\"Speech of Unity at Iceberg Summit\", \"Speech\", \"Chancellor Icybeak\", 1433),\n",
    "    (\"Chronicler's Account of the Great Migration\", \"Chronicle\", \"Chronicler Flipper\", 1398),\n",
    "    (\"Treaty of the Icy Shores\", \"Edict\", \"Council of Penguins\", 1280),\n",
    "    (\"Diary of Scholar Snowfoot\", \"Diary\", \"Scholar Snowfoot\", 1277),\n",
    "    (\"Speech at the Glacial Gathering\", \"Speech\", \"Emperor Icebeak\", 1225),\n",
    "    (\"Letter from Healer Frostbill\", \"Letter\", \"Healer Frostbill\", 1345),\n",
    "    (\"Chronicler's Record of the Frost Wars\", \"Chronicle\", \"Chronicler Flipper\", 1403),\n",
    "    (\"Proclamation of the Icebound Pact\", \"Edict\", \"Empress Frostwing\", 1195)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly with the collection, we may want to group the documents by their type. To do that we have to loop through the entire list of documents and add them to a set under the name of the document type..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Letter': [('Letter from Emperor Icebeak', 'Emperor Icebeak', 1203), ('Letter from Admiral Snowclaw', 'Admiral Snowclaw', 1256), ('Letter from Healer Frostbill', 'Healer Frostbill', 1345)], 'Diary': [('Diary of Explorer Frostfeather', 'Explorer Frostfeather', 1302), ('Diary of Fisher Penguino', 'Fisher Penguino', 1320), ('Diary of Scholar Snowfoot', 'Scholar Snowfoot', 1277)], 'Edict': [('Proclamation of the Great Snowfall', 'Council of Penguins', 1150), ('Edict of the Eternal Winter', 'Empress Frostwing', 1189), ('Treaty of the Icy Shores', 'Council of Penguins', 1280), ('Proclamation of the Icebound Pact', 'Empress Frostwing', 1195)], 'Chronicle': [(\"Chronicler's Tale of the Frozen Flock\", 'Chronicler Flipper', 1401), (\"Chronicler's Account of the Great Migration\", 'Chronicler Flipper', 1398), (\"Chronicler's Record of the Frost Wars\", 'Chronicler Flipper', 1403)], 'Speech': [('Speech of Unity at Iceberg Summit', 'Chancellor Icybeak', 1433), ('Speech at the Glacial Gathering', 'Emperor Icebeak', 1225)]}\n"
     ]
    }
   ],
   "source": [
    "documents_by_type = {}\n",
    "\n",
    "for title, doc_type, author, year in documents:\n",
    "    if doc_type not in documents_by_type:\n",
    "        documents_by_type[doc_type] = []\n",
    "    documents_by_type[doc_type].append((title, author, year))\n",
    "\n",
    "print(documents_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to ensure that our documents are the most clean possible and so next we clean ensure that all our data is cleaned and in the specific type we want it. For this we can use a list comprehension..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Letter from Emperor Icebeak', 'Letter', 'Emperor Icebeak', '1203'), ('Diary of Explorer Frostfeather', 'Diary', 'Explorer Frostfeather', '1302'), ('Proclamation of the Great Snowfall', 'Edict', 'Council Of Penguins', '1150'), (\"Chronicler's Tale of the Frozen Flock\", 'Chronicle', 'Chronicler Flipper', '1401'), ('Letter from Admiral Snowclaw', 'Letter', 'Admiral Snowclaw', '1256'), ('Edict of the Eternal Winter', 'Edict', 'Empress Frostwing', '1189'), ('Diary of Fisher Penguino', 'Diary', 'Fisher Penguino', '1320'), ('Speech of Unity at Iceberg Summit', 'Speech', 'Chancellor Icybeak', '1433'), (\"Chronicler's Account of the Great Migration\", 'Chronicle', 'Chronicler Flipper', '1398'), ('Treaty of the Icy Shores', 'Edict', 'Council Of Penguins', '1280'), ('Diary of Scholar Snowfoot', 'Diary', 'Scholar Snowfoot', '1277'), ('Speech at the Glacial Gathering', 'Speech', 'Emperor Icebeak', '1225'), ('Letter from Healer Frostbill', 'Letter', 'Healer Frostbill', '1345'), (\"Chronicler's Record of the Frost Wars\", 'Chronicle', 'Chronicler Flipper', '1403'), ('Proclamation of the Icebound Pact', 'Edict', 'Empress Frostwing', '1195')]\n"
     ]
    }
   ],
   "source": [
    "cleaned_documents = [(title, doc_type, author.title(), str(year)) for title, doc_type, author, year in documents]\n",
    "\n",
    "print(cleaned_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the clean data, we may be interested in investigating the collection as a whole. For example, finding how many of each type of document we have, or perhaps what the earliest document is in the collection..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Counts by Type: {'Letter': 3, 'Diary': 3, 'Edict': 4, 'Chronicle': 3, 'Speech': 2}\n",
      "Earliest Document: ('Proclamation of the Great Snowfall', 'Edict', 'Council Of Penguins', '1150')\n"
     ]
    }
   ],
   "source": [
    "# We open up here an empty set, and set earliest_document to None in order to have a \n",
    "# placeholder for the earliest document.\n",
    "document_counts = {}\n",
    "earliest_document = None\n",
    "\n",
    "for title, doc_type, author, year in cleaned_documents:\n",
    "    # This bit counts the documents.\n",
    "    if doc_type not in document_counts:\n",
    "        document_counts[doc_type] = 0\n",
    "    document_counts[doc_type] += 1\n",
    "    # This bit does the check for the earliest document.\n",
    "    if earliest_document is None or int(year) < int(earliest_document[3]):\n",
    "        earliest_document = (title, doc_type, author, year)\n",
    "\n",
    "print(\"Document Counts by Type:\", document_counts)\n",
    "print(\"Earliest Document:\", earliest_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps in examining the collection we are more interested in a very specific ancient penguin author. We can do a deep dive with what we have already learnt..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents by Emperor Icebeak: [('Letter from Emperor Icebeak', 'Letter', '1203'), ('Speech at the Glacial Gathering', 'Speech', '1225')]\n",
      "Emperor Icebeak Document Counts by Type: {'Letter': 1, 'Speech': 1}\n"
     ]
    }
   ],
   "source": [
    "# Extract documents authored by Emperor Icebeak using list comprehension\n",
    "icebeak_documents = [(title, doc_type, year) for title, doc_type, author, year in cleaned_documents if author == \"Emperor Icebeak\"]\n",
    "\n",
    "print(\"Documents by Emperor Icebeak:\", icebeak_documents)\n",
    "\n",
    "# Analyze the types of documents authored by Emperor Icebeak\n",
    "icebeak_document_types = [doc_type for title, doc_type, year in icebeak_documents]\n",
    "\n",
    "# Manually count the occurrences of each document type\n",
    "icebeak_document_counts = {}\n",
    "for doc_type in icebeak_document_types:\n",
    "    if doc_type not in icebeak_document_counts:\n",
    "        icebeak_document_counts[doc_type] = 0\n",
    "    icebeak_document_counts[doc_type] += 1\n",
    "\n",
    "print(\"Emperor Icebeak Document Counts by Type:\", icebeak_document_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
